---
title: "Tidy up the data"
subtitle: "From measurements taken by a Walz Diving PAMII"
author: "Sarah Tanja"
date: "`r format(Sys.time(), '%d %B, %Y')`"  
format:
  html:
    df-print: paged
    toc: true
    toc-location: right
    smooth-scroll: true
    link-external-icon: true
    link-external-newwindow: true
    code-fold: false
    code-tools: true
    code-copy: true
    highlight-style: breeze
    code-overflow: wrap
    theme: minty
editor: 
  markdown: 
    wrap: 72
---

# Overview

Quasi dark-adapted rapid light curve analysis from measurements taken by
a Walz Diving PAMII...

# Install and load packages

```{r}
# Install packages
if ("tidyverse" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyverse')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("stringr" %in% rownames(installed.packages()) == 'FALSE') install.packages('stringr')

# Load packages
library(dplyr)
library(tidyverse)
library(lubridate)
library(stringr)
```

# Pull in metadata

This metadata should contain the specific information about the
treatment each specimen of *Anthopleura elegantissima* was exposed to,
and the very important `No.` column which maps to the `No.` column in
the Walz PAM output report, and allows us to link specimens to the data
we collected for them via the PAM.

We've done this consecutively and with repeated measures across 5 days
(here we will likely exclude the pre-exposure measurements from the
final analysis because they were taken with a less refined method.. The
pre-exposure measurements were taken using just the 60$^o$ 5mm sample
adapter in a fully dark-adapted state, however, the small size of the
anemones and their proclivity to squish themselves into the corners of
their jars and the inner curves of the petri dishes made it difficult to
get standardized distances from the anemones to the tip of the fiber
optic fluorometer). We solved this in later measurements by 3D-printing
and using a custom 60$^o$ 5mm adapter with a reduced 'base-plate' so it
could fit directly on the anemones in corners and tight spots. We also
switched from fully dark-adapted rapid light curves (dark adapted for at
least 40 min) to quasi dark-adapted rapid light curves (dark adapted for
20 seconds). Since we plan to use this method in field applications in
ambient light conditions, it's logistically advantageous to measure
rapid light curves during daylight hours.

Here we pull in the metadata for each day of rapid light curve
measurements taken prior to, and daily during, the experiment.

```{r}
metadata_0619 <- read_csv("../metadata/rlc_metadata_06192024.csv")
metadata_0620 <- read_csv("../metadata/rlc_metadata_06202024.csv")
metadata_0621 <- read_csv("../metadata/rlc_metadata_06212024.csv")
metadata_0622 <- read_csv("../metadata/rlc_metadata_06222024.csv")
```

Each metadata file should have 60 observations.

# Pull in data

This data is generated by the report tab in the Win-3 Control Software
of the Walz Diving PAM II. Of importance to note is that regression 1
(REG1) and regression 2 (REG2) for each light curve are listed above the
tabular light curve data.

```{r}
rlc_0619 <- read_csv("../pam-data/rlc_06192024.csv")
rlc_0620 <- read_csv("../pam-data/rlc_06202024.csv")
rlc_0621 <- read_csv("../pam-data/rlc_06212024.csv")
rlc_0622 <- read_csv("../pam-data/rlc_06222024.csv")
```

# Join & filter data

Join metadata to the PAM data by matching "No." in the rlc dataframe to
"No." in the corresponding rlc dataframe

```{r}
rlc_0619 <- left_join(rlc_0619, metadata_0619, by = "No.") 
rlc_0620 <- left_join(rlc_0620, metadata_0620, by = "No.") 
rlc_0621 <- left_join(rlc_0621, metadata_0621, by = "No.") 
rlc_0622 <- left_join(rlc_0622, metadata_0622, by = "No.") 
```

## QAQC

sample_id list

```{r}
sample_id <- metadata_0619$sample_id
```

each should have 60 'matches' of sample ID to light curve start

```{r}
rlc_0619 %>% filter(!is.na(sample_id))
rlc_0620 %>% filter(!is.na(sample_id))
rlc_0621 %>% filter(!is.na(sample_id))
rlc_0622 %>% filter(!is.na(sample_id))
```

# Section data

## Identify start and end indices, & extract RLC's

Markers for each RLC (inclusive of regression rows)

#### Day 1 \| June 19th 2024

```{r}
# Identify the start and end indices (aka dataframe rows) for each RLC
start_indices <- which(rlc_0619$Sync == "LCS")-2 # here we subtract 2 'rows' from the rapid light curve start row to include REG1 and REG2
end_indices <- which(rlc_0619$Sync == "LCE")
```

Each RLC should be inclusive of the start and end markers and the
regression data. We'll use a loop to go through each start and end pair

```{r}
# Initialize a list to store the dataframes
list_rlc_0619 <- list()

# Loop through each start and end index pair
for (i in seq_along(start_indices)) {
  # Extract the chunk
  chunk <- rlc_0619[(start_indices[i]):(end_indices[i]), , drop = FALSE]
  
  # Store the dataframe in the list
  list_rlc_0619[[i]] <- chunk
}
```

#### Day 2 \| June 20th 2024

```{r}
# Identify the start and end indices (aka dataframe rows) for each RLC
start_indices <- which(rlc_0620$Sync == "LCS")-2 # here we subtract 2 'rows' from the rapid light curve start row to include REG1 and REG2
end_indices <- which(rlc_0620$Sync == "LCE")
```

```{r}
# Initialize a list to store the dataframes
list_rlc_0620 <- list()

# Loop through each start and end index pair
for (i in seq_along(start_indices)) {
  # Extract the chunk
  chunk <- rlc_0620[(start_indices[i]):(end_indices[i]), , drop = FALSE]
  
  # Store the dataframe in the list
  list_rlc_0620[[i]] <- chunk
}
```

#### Day 3 \| June 21st 2024

```{r}
# Identify the start and end indices (aka dataframe rows) for each RLC
start_indices <- which(rlc_0621$Sync == "LCS")-2 # here we subtract 2 'rows' from the rapid light curve start row to include REG1 and REG2
end_indices <- which(rlc_0621$Sync == "LCE")
```

```{r}
# Initialize a list to store the dataframes
list_rlc_0621 <- list()

# Loop through each start and end index pair
for (i in seq_along(start_indices)) {
  # Extract the chunk
  chunk <- rlc_0621[(start_indices[i]):(end_indices[i]), , drop = FALSE]
  
  # Store the dataframe in the list
  list_rlc_0621[[i]] <- chunk
}
```

#### Day 4 \| June 2nd 2024

```{r}
# Identify the start and end indices (aka dataframe rows) for each RLC
start_indices <- which(rlc_0622$Sync == "LCS")-2 # here we subtract 2 'rows' from the rapid light curve start row to include REG1 and REG2
end_indices <- which(rlc_0622$Sync == "LCE")
```

```{r}
# Initialize a list to store the dataframes
list_rlc_0622 <- list()

# Loop through each start and end index pair
for (i in seq_along(start_indices)) {
  # Extract the chunk
  chunk <- rlc_0622[(start_indices[i]):(end_indices[i]), , drop = FALSE]
  
  # Store the dataframe in the list
  list_rlc_0622[[i]] <- chunk
}
```

## Fill in metadata to all rows

Use a loop to iterate through the list of dataframes and apply fill() to
each metadata variable we want filled in

```{r}
for (i in seq_along(list_rlc_0619)){
  list_rlc_0619[[i]] <- list_rlc_0619[[i]] %>% 
    fill(sample_id, .direction = "up") %>%
    fill(sample_id, .direction = "down") %>% 
    fill(condition, .direction = "up") %>%
    fill(condition, .direction = "down") %>%
    fill(date, .direction = "up") %>% 
    fill(date, .direction = "down") %>% 
    fill(temp, .direction = "up") %>% 
    fill(temp, .direction = "down") %>%
    fill(aggregate, .direction = "up") %>%
    fill(aggregate, .direction = "down") %>%
    fill(leachate, .direction = "up") %>%
    fill(leachate, .direction = "down") %>%
    fill(notes, .direction = "up") %>%
    fill(notes, .direction = "down") %>%
    fill(species, .direction = "up") %>% 
    fill(species, .direction = "down")
}
```

```{r}
for (i in seq_along(list_rlc_0620)){
  list_rlc_0620[[i]] <- list_rlc_0620[[i]] %>% 
    fill(sample_id, .direction = "up") %>%
    fill(sample_id, .direction = "down") %>% 
    fill(condition, .direction = "up") %>%
    fill(condition, .direction = "down") %>%
    fill(date, .direction = "up") %>% 
    fill(date, .direction = "down") %>% 
    fill(temp, .direction = "up") %>% 
    fill(temp, .direction = "down") %>%
    fill(aggregate, .direction = "up") %>%
    fill(aggregate, .direction = "down") %>%
    fill(leachate, .direction = "up") %>%
    fill(leachate, .direction = "down") %>%
    fill(notes, .direction = "up") %>%
    fill(notes, .direction = "down") %>%
    fill(species, .direction = "up") %>% 
    fill(species, .direction = "down")
}
```

```{r}
for (i in seq_along(list_rlc_0621)){
  list_rlc_0621[[i]] <- list_rlc_0621[[i]] %>% 
    fill(sample_id, .direction = "up") %>%
    fill(sample_id, .direction = "down") %>% 
    fill(condition, .direction = "up") %>%
    fill(condition, .direction = "down") %>%
    fill(date, .direction = "up") %>% 
    fill(date, .direction = "down") %>% 
    fill(temp, .direction = "up") %>% 
    fill(temp, .direction = "down") %>%
    fill(aggregate, .direction = "up") %>%
    fill(aggregate, .direction = "down") %>%
    fill(leachate, .direction = "up") %>%
    fill(leachate, .direction = "down") %>%
    fill(notes, .direction = "up") %>%
    fill(notes, .direction = "down") %>%
    fill(species, .direction = "up") %>% 
    fill(species, .direction = "down")
}
```

```{r}
for (i in seq_along(list_rlc_0622)){
  list_rlc_0622[[i]] <- list_rlc_0622[[i]] %>% 
    fill(sample_id, .direction = "up") %>%
    fill(sample_id, .direction = "down") %>% 
    fill(condition, .direction = "up") %>%
    fill(condition, .direction = "down") %>%
    fill(date, .direction = "up") %>% 
    fill(date, .direction = "down") %>% 
    fill(temp, .direction = "up") %>% 
    fill(temp, .direction = "down") %>%
    fill(aggregate, .direction = "up") %>%
    fill(aggregate, .direction = "down") %>%
    fill(leachate, .direction = "up") %>%
    fill(leachate, .direction = "down") %>%
    fill(notes, .direction = "up") %>%
    fill(notes, .direction = "down") %>%
    fill(species, .direction = "up") %>% 
    fill(species, .direction = "down")
}
```

# Extract alpha, ETRm, & Ik values

```{r}
# Define a regex pattern to extract alpha, ETRm, and Ik values
regex <- "alpha: ([\\d.-]+), ETRm: ([\\d.-]+), Ik: ([\\d.-]+)"
```

### Day 1 \| regression_0619

```{r}
# Initialize a regression dataframe
regression_0619 <- data.frame()

# Extract the rows that match the pattern
for (i in seq_along(list_rlc_0619)){
  jasby_platt <- list_rlc_0619[[i]] %>%
  mutate(match = str_extract(`1:F`, regex)) %>%
  mutate(alpha = str_extract(match, "(?<=alpha: )[\\d.-]+"),
         ETRm = str_extract(match, "(?<=ETRm: )[\\d.-]+"),
         Ik = str_extract(match, "(?<=Ik: )[\\d.-]+")) %>% 
    select(Date, Time, Type, sample_id, condition, temp, aggregate, leachate,'1:F', alpha, ETRm, Ik) %>% 
    #filter(Type %in% c('REG1','REG2')) %>% 
    filter(Type %in% 'REG2') %>%
    filter(!is.na(sample_id)) %>% 
    mutate(days_of_exposure = 1) %>% 
    mutate(treatment = str_c(temp, leachate, sep = "_")) %>% 
    mutate(treatment = as.factor(treatment)) %>% 
    mutate(alpha = as.numeric(alpha)) %>% 
    mutate(ETRm = as.numeric(ETRm)) %>% 
    mutate(Ik = as.numeric(Ik))
  
  # Append the modified dataframe to the regression_0619 data frame
  regression_0619 <- bind_rows(regression_0619, jasby_platt)
}
```

### Day 2 \| regression_0620

```{r}
# Initialize a regression dataframe
regression_0620 <- data.frame()

# Extract the rows that match the pattern
for (i in seq_along(list_rlc_0620)){
  jasby_platt <- list_rlc_0620[[i]] %>%
  mutate(match = str_extract(`1:F`, regex)) %>%
  mutate(alpha = str_extract(match, "(?<=alpha: )[\\d.-]+"),
         ETRm = str_extract(match, "(?<=ETRm: )[\\d.-]+"),
         Ik = str_extract(match, "(?<=Ik: )[\\d.-]+")) %>% 
    select(Date, Time, Type, sample_id, condition, temp, aggregate, leachate,'1:F', alpha, ETRm, Ik) %>% 
    #filter(Type %in% c('REG1','REG2')) %>% 
    filter(Type %in% 'REG2') %>%
    filter(!is.na(sample_id)) %>% 
    mutate(days_of_exposure = 2) %>% 
    mutate(treatment = str_c(temp, leachate, sep = "_")) %>% 
    mutate(treatment = as.factor(treatment)) %>% 
    mutate(alpha = as.numeric(alpha)) %>% 
    mutate(ETRm = as.numeric(ETRm)) %>% 
    mutate(Ik = as.numeric(Ik))
  
  # Append the modified dataframe to the regression_0620 data frame
  regression_0620 <- bind_rows(regression_0620, jasby_platt)
}
```

> Why are there only 57 rows!?

### Day 3 \| regression_0621

```{r}
# Initialize a regression dataframe
regression_0621 <- data.frame()

# Extract the rows that match the pattern
for (i in seq_along(list_rlc_0621)){
  jasby_platt <- list_rlc_0621[[i]] %>%
  mutate(match = str_extract(`1:F`, regex)) %>%
  mutate(alpha = str_extract(match, "(?<=alpha: )[\\d.-]+"),
         ETRm = str_extract(match, "(?<=ETRm: )[\\d.-]+"),
         Ik = str_extract(match, "(?<=Ik: )[\\d.-]+")) %>% 
    select(Date, Time, Type, sample_id, condition, temp, aggregate, leachate,'1:F', alpha, ETRm, Ik) %>% 
    #filter(Type %in% c('REG1','REG2')) %>% 
    filter(Type %in% 'REG2') %>%
    filter(!is.na(sample_id)) %>% 
    mutate(days_of_exposure = 3) %>% 
    mutate(treatment = str_c(temp, leachate, sep = "_")) %>% 
    mutate(treatment = as.factor(treatment)) %>% 
    mutate(alpha = as.numeric(alpha)) %>% 
    mutate(ETRm = as.numeric(ETRm)) %>% 
    mutate(Ik = as.numeric(Ik))
  
  # Append the modified dataframe to the regression_0621 data frame
  regression_0621 <- bind_rows(regression_0621, jasby_platt)
}
```

> Why are there only 58 rows!?

### Day 4 \| regression_0622

```{r}
# Initialize a regression dataframe
regression_0622 <- data.frame()

# Extract the rows that match the pattern
for (i in seq_along(list_rlc_0622)){
  jasby_platt <- list_rlc_0622[[i]] %>%
  mutate(match = str_extract(`1:F`, regex)) %>%
  mutate(alpha = str_extract(match, "(?<=alpha: )[\\d.-]+"),
         ETRm = str_extract(match, "(?<=ETRm: )[\\d.-]+"),
         Ik = str_extract(match, "(?<=Ik: )[\\d.-]+")) %>% 
    select(Date, Time, Type, sample_id, condition, temp, aggregate, leachate,'1:F', alpha, ETRm, Ik) %>% 
    #filter(Type %in% c('REG1','REG2')) %>% 
    filter(Type %in% 'REG2') %>%
    filter(!is.na(sample_id)) %>% 
    mutate(days_of_exposure = 4) %>% 
    mutate(treatment = str_c(temp, leachate, sep = "_")) %>% 
    mutate(treatment = as.factor(treatment)) %>% 
    mutate(alpha = as.numeric(alpha)) %>% 
    mutate(ETRm = as.numeric(ETRm)) %>% 
    mutate(Ik = as.numeric(Ik))
  
  # Append the modified dataframe to the regression_0621 data frame
  regression_0622 <- bind_rows(regression_0622, jasby_platt)
}
```

> Why are there only 58 rows!?

# Save regression dataframes as .csv

```{r}
write.csv(regression_0619, file = "../output/reg_day1.csv" )
write.csv(regression_0620, file = "../output/reg_day2.csv" )
write.csv(regression_0621, file = "../output/reg_day3.csv" )
write.csv(regression_0622, file = "../output/reg_day4.csv" )
```

::: callout-important
Tidy up Fv/Fm data from dark-adapted measurements in
`01.2_fvfm_tidy_data.qmd`.

Proceed with analysis of calculated RLC regression variables from Jasby
& Platt (1976) (rERTm, Ik, Alpha) and dark adapted quantum yield (Fv/Fm)
by running two-way anovas and doing initial data visualization in
`02_anovas.qmd`
:::
